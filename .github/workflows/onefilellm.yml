name: OneFileLLM Content Aggregator

on:
  workflow_dispatch:
    inputs:
      sources:
        description: 'Input sources (space-separated URLs, paths, or GitHub repos)'
        required: true
        type: string
      output_name:
        description: 'Output filename (without extension, alphanumeric/dash/underscore only)'
        required: false
        default: 'aggregated-content'
        type: string
      format:
        description: 'Output format override'
        required: false
        type: choice
        options:
          - auto
          - text
          - markdown
          - json
          - html
          - yaml
        default: auto
      crawl_depth:
        description: 'Max crawl depth for web URLs'
        required: false
        default: '3'
        type: string
      crawl_max_pages:
        description: 'Max pages to crawl'
        required: false
        default: '100'
        type: string

  # Allow calling from other workflows
  workflow_call:
    inputs:
      sources:
        description: 'Input sources (space-separated URLs, paths, or GitHub repos)'
        required: true
        type: string
      output_name:
        description: 'Output filename (without extension, alphanumeric/dash/underscore only)'
        required: false
        default: 'aggregated-content'
        type: string
      format:
        description: 'Output format override'
        required: false
        type: string
        default: auto
      crawl_depth:
        description: 'Max crawl depth for web URLs'
        required: false
        default: '3'
        type: string
      crawl_max_pages:
        description: 'Max pages to crawl'
        required: false
        default: '100'
        type: string
    outputs:
      output_file:
        description: 'Path to the generated output file'
        value: ${{ jobs.aggregate.outputs.output_file }}
      token_count:
        description: 'Estimated token count'
        value: ${{ jobs.aggregate.outputs.token_count }}
      pr_url:
        description: 'URL of the created pull request'
        value: ${{ jobs.commit-and-merge.outputs.pr_url }}

permissions:
  contents: write
  pull-requests: write

jobs:
  aggregate:
    name: Aggregate Content
    runs-on: ubuntu-latest
    outputs:
      output_file: ${{ steps.run.outputs.output_file }}
      token_count: ${{ steps.run.outputs.token_count }}
      branch_name: ${{ steps.branch.outputs.name }}
      safe_output_name: ${{ steps.validate.outputs.safe_output_name }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Validate and sanitize inputs
        id: validate
        env:
          INPUT_OUTPUT_NAME: ${{ inputs.output_name }}
          INPUT_CRAWL_DEPTH: ${{ inputs.crawl_depth }}
          INPUT_CRAWL_MAX_PAGES: ${{ inputs.crawl_max_pages }}
          INPUT_FORMAT: ${{ inputs.format }}
          INPUT_SOURCES: ${{ inputs.sources }}
        run: |
          # Sanitize output_name: only allow alphanumeric, dash, underscore
          SAFE_OUTPUT_NAME=$(echo "$INPUT_OUTPUT_NAME" | tr -cd '[:alnum:]-_')
          if [ -z "$SAFE_OUTPUT_NAME" ]; then
            SAFE_OUTPUT_NAME="aggregated-content"
          fi
          echo "safe_output_name=${SAFE_OUTPUT_NAME}" >> $GITHUB_OUTPUT

          # Validate crawl_depth is a number
          if ! [[ "$INPUT_CRAWL_DEPTH" =~ ^[0-9]+$ ]]; then
            echo "Error: crawl_depth must be a positive integer"
            exit 1
          fi

          # Validate crawl_max_pages is a number
          if ! [[ "$INPUT_CRAWL_MAX_PAGES" =~ ^[0-9]+$ ]]; then
            echo "Error: crawl_max_pages must be a positive integer"
            exit 1
          fi

          # Validate format is one of the allowed values
          case "$INPUT_FORMAT" in
            auto|text|markdown|json|html|yaml) ;;
            *)
              echo "Error: format must be one of: auto, text, markdown, json, html, yaml"
              exit 1
              ;;
          esac

          # Validate sources to prevent argument injection (Issue #1)
          # Check that no source starts with a dash to prevent flag injection
          for source in $INPUT_SOURCES; do
            if [[ "$source" =~ ^- ]]; then
              echo "Error: Source '$source' starts with a dash. This is not allowed to prevent argument injection."
              exit 1
            fi
          done

          # Validate URLs to prevent SSRF (Issue #2)
          # Block private IP ranges, loopback, and cloud metadata services
          for source in $INPUT_SOURCES; do
            # Extract URL scheme and host if it looks like a URL
            if [[ "$source" =~ ^https?:// ]]; then
              # Extract hostname from URL
              hostname=$(echo "$source" | sed -E 's|^https?://([^/:]+).*|\1|')

              # Block loopback addresses
              if [[ "$hostname" =~ ^(localhost|127\.|0\.0\.0\.0) ]]; then
                echo "Error: Source '$source' targets loopback address. This is not allowed for security reasons."
                exit 1
              fi

              # Block private IP ranges (RFC1918)
              if [[ "$hostname" =~ ^10\. ]] || \
                 [[ "$hostname" =~ ^192\.168\. ]] || \
                 [[ "$hostname" =~ ^172\.(1[6-9]|2[0-9]|3[0-1])\. ]]; then
                echo "Error: Source '$source' targets private IP range. This is not allowed for security reasons."
                exit 1
              fi

              # Block cloud metadata services
              if [[ "$hostname" =~ ^169\.254\.169\.254 ]] || \
                 [[ "$hostname" =~ ^metadata\. ]] || \
                 [[ "$hostname" = "metadata" ]]; then
                echo "Error: Source '$source' targets cloud metadata service. This is not allowed for security reasons."
                exit 1
              fi

              # Block link-local addresses
              if [[ "$hostname" =~ ^169\.254\. ]]; then
                echo "Error: Source '$source' targets link-local address. This is not allowed for security reasons."
                exit 1
              fi
            fi
          done

          echo "Inputs validated successfully"

      - name: Generate branch name
        id: branch
        run: |
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          BRANCH_NAME="onefilellm/output-${TIMESTAMP}"
          echo "name=${BRANCH_NAME}" >> $GITHUB_OUTPUT
          echo "Branch name: ${BRANCH_NAME}"

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: 'tools/onefilellm/requirements.txt'

      - name: Install onefilellm
        run: |
          pip install -r tools/onefilellm/requirements.txt
          # Verify installation
          onefilellm --help || python -m onefilellm --help

      - name: Run onefilellm
        id: run
        env:
          GITHUB_TOKEN: ${{ secrets.GH_TOKEN || secrets.GITHUB_TOKEN }}
          INPUT_SOURCES: ${{ inputs.sources }}
          INPUT_FORMAT: ${{ inputs.format }}
          INPUT_CRAWL_DEPTH: ${{ inputs.crawl_depth }}
          INPUT_CRAWL_MAX_PAGES: ${{ inputs.crawl_max_pages }}
          SAFE_OUTPUT_NAME: ${{ steps.validate.outputs.safe_output_name }}
        run: |
          # Create docs directory if it doesn't exist
          mkdir -p docs/onefilellm

          # Build command arguments array for safety
          ARGS=()

          # Add format if not auto
          if [ "$INPUT_FORMAT" != "auto" ]; then
            ARGS+=("-f" "$INPUT_FORMAT")
          fi

          # Add crawl options
          ARGS+=("--crawl-max-depth" "$INPUT_CRAWL_DEPTH")
          ARGS+=("--crawl-max-pages" "$INPUT_CRAWL_MAX_PAGES")

          OUTPUT_FILE="docs/onefilellm/${SAFE_OUTPUT_NAME}.xml"

          echo "Running onefilellm with validated inputs..."

          # Execute using array expansion for safety
          # Use -- separator to prevent argument injection (sources validated in earlier step)
          # Note: INPUT_SOURCES is intentionally not quoted to allow space-separated sources
          if onefilellm "${ARGS[@]}" -- $INPUT_SOURCES > "$OUTPUT_FILE" 2>&1; then
            echo "onefilellm completed successfully"
          else
            # If direct output fails, try with python -m
            python -m onefilellm "${ARGS[@]}" -- $INPUT_SOURCES > "$OUTPUT_FILE" 2>&1 || {
              echo "Error: onefilellm failed"
              cat "$OUTPUT_FILE"
              exit 1
            }
          fi

          # Check if output was generated
          if [ -f "$OUTPUT_FILE" ] && [ -s "$OUTPUT_FILE" ]; then
            echo "output_file=${OUTPUT_FILE}" >> $GITHUB_OUTPUT

            # Estimate token count (rough approximation: chars / 4)
            CHARS=$(wc -c < "$OUTPUT_FILE")
            TOKENS=$((CHARS / 4))
            echo "token_count=$TOKENS" >> $GITHUB_OUTPUT

            echo "Generated output with ~$TOKENS estimated tokens"
            echo "File size: $(du -h "$OUTPUT_FILE" | cut -f1)"
          else
            echo "Error: No output generated"
            exit 1
          fi

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ steps.validate.outputs.safe_output_name }}
          path: docs/onefilellm/${{ steps.validate.outputs.safe_output_name }}.xml
          retention-days: 30

  commit-and-merge:
    name: Commit, PR, and Merge
    needs: aggregate
    runs-on: ubuntu-latest
    outputs:
      pr_url: ${{ steps.create-pr.outputs.pull-request-url }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GH_TOKEN || secrets.GITHUB_TOKEN }}

      - name: Download artifact
        uses: actions/download-artifact@v4
        with:
          name: ${{ needs.aggregate.outputs.safe_output_name }}
          path: docs/onefilellm/

      - name: Create branch and commit
        id: commit
        env:
          BRANCH_NAME: ${{ needs.aggregate.outputs.branch_name }}
          SAFE_OUTPUT_NAME: ${{ needs.aggregate.outputs.safe_output_name }}
          TOKEN_COUNT: ${{ needs.aggregate.outputs.token_count }}
          INPUT_SOURCES: ${{ inputs.sources }}
        run: |
          # Configure git
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # Create and switch to new branch
          git checkout -b "$BRANCH_NAME"

          # Add the output file
          git add docs/onefilellm/

          # Commit with safe message (sources shown for reference only)
          git commit -m "docs: add OneFileLLM aggregated content

          Output: docs/onefilellm/${SAFE_OUTPUT_NAME}.xml
          Tokens: ~${TOKEN_COUNT}

          [skip ci]"

          # Push the branch
          git push -u origin "$BRANCH_NAME"

          echo "branch=${BRANCH_NAME}" >> $GITHUB_OUTPUT

      - name: Create Pull Request
        id: create-pr
        env:
          GH_TOKEN: ${{ secrets.GH_TOKEN || secrets.GITHUB_TOKEN }}
          BRANCH_NAME: ${{ needs.aggregate.outputs.branch_name }}
          SAFE_OUTPUT_NAME: ${{ needs.aggregate.outputs.safe_output_name }}
          TOKEN_COUNT: ${{ needs.aggregate.outputs.token_count }}
        run: |
          PR_BODY="## OneFileLLM Content Aggregation

          **Output file:** \`docs/onefilellm/${SAFE_OUTPUT_NAME}.xml\`

          **Estimated tokens:** ~${TOKEN_COUNT}

          ---
          *Auto-generated by OneFileLLM workflow*"

          PR_URL=$(gh pr create \
            --title "docs: add OneFileLLM output - ${SAFE_OUTPUT_NAME}" \
            --body "$PR_BODY" \
            --head "$BRANCH_NAME" \
            --base main)

          echo "pull-request-url=${PR_URL}" >> $GITHUB_OUTPUT
          echo "Created PR: ${PR_URL}"

      - name: Auto-merge Pull Request
        id: merge
        continue-on-error: true
        env:
          GH_TOKEN: ${{ secrets.GH_TOKEN || secrets.GITHUB_TOKEN }}
          PR_URL: ${{ steps.create-pr.outputs.pull-request-url }}
        run: |
          # Try to enable auto-merge (squash)
          # This may fail if:
          # - Token lacks admin/write permissions
          # - Auto-merge is not enabled on the repo
          # - Branch protection rules prevent it
          if gh pr merge "$PR_URL" --squash --auto --delete-branch 2>&1; then
            echo "auto_merged=true" >> $GITHUB_OUTPUT
            echo "Auto-merge enabled for $PR_URL"
          else
            echo "auto_merged=false" >> $GITHUB_OUTPUT
            echo "Auto-merge not available (likely insufficient permissions or repo settings)"
            echo "PR created successfully - manual merge required: $PR_URL"
          fi

      - name: Summary
        env:
          SAFE_OUTPUT_NAME: ${{ needs.aggregate.outputs.safe_output_name }}
          TOKEN_COUNT: ${{ needs.aggregate.outputs.token_count }}
          PR_URL: ${{ steps.create-pr.outputs.pull-request-url }}
          AUTO_MERGED: ${{ steps.merge.outputs.auto_merged }}
        run: |
          {
            echo "## OneFileLLM Output Summary"
            echo ""
            echo "**Output file:** \`docs/onefilellm/${SAFE_OUTPUT_NAME}.xml\`"
            echo ""
            echo "**Estimated tokens:** ~${TOKEN_COUNT}"
            echo ""
            echo "**Pull Request:** ${PR_URL}"
            echo ""
            if [ "$AUTO_MERGED" == "true" ]; then
              echo "The PR will be auto-merged and the branch deleted."
            else
              echo "**Note:** Auto-merge not available. Please merge the PR manually."
            fi
          } >> $GITHUB_STEP_SUMMARY
