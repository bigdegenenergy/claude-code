# ⚠️ REVIEW INSTRUCTIONS

> Generated by Gemini

```json
{
  "review": {
    "summary": "The PR introduces a new workflow for aggregating external content (`onefilellm`) with high-privilege permissions (contents:write, pull-requests:write). Critical security vulnerabilities were identified: Argument Injection via the `sources` input allows overriding tool behavior, and the combination of SSRF (scraping internal/metadata URLs) with auto-commit can leak runner credentials. The auto-merge behavior for untrusted external content is also unsafe.",
    "decision": "REQUEST_CHANGES"
  },
  "issues": [
    {
      "id": 1,
      "severity": "critical",
      "file": ".github/workflows/onefilellm.yml",
      "line": 1,
      "title": "Argument Injection via 'sources' input",
      "description": "The `sources` input is split into an array and passed directly to the `onefilellm` command. Users can inject flags by including strings starting with dashes (e.g., `--output-file ...`, `--max-pages 100000`) within the `sources` string. Since most Python CLI libraries (like `argparse`) accept flags interspersed with positional arguments, this allows an attacker to bypass validation logic (like `max_pages` limits) or overwrite arbitrary files if the tool supports output path flags.",
      "suggestion": "Validate that no entry in the `sources` array starts with a dash (`-`). Additionally, use the double-dash separator (`--`) in the command execution line (e.g., `onefilellm [options] -- \"${source_array[@]}\"`) to explicitly treat subsequent arguments as positional inputs, if the tool supports it."
    },
    {
      "id": 2,
      "severity": "high",
      "file": ".github/workflows/onefilellm.yml",
      "line": 1,
      "title": "SSRF and Credential Leakage Risk",
      "description": "The workflow executes a scraper on user-controlled URLs within the GitHub Actions runner. This permits Server-Side Request Forgery (SSRF). A malicious actor (or accidental misuse) could target cloud metadata services (e.g., `http://169.254.169.254/latest/meta-data/`) or internal loopback interfaces. Since the workflow automatically commits and merges the output into the repository, sensitive runner credentials or internal network data could be publicly exposed.",
      "suggestion": "Implement strict validation for URLs in `sources` to block requests to private IP ranges (RFC1918), loopback addresses, and known cloud metadata IPs. Alternatively, run the scraping job in a container with restricted network access, though this may impede the tool's functionality."
    },
    {
      "id": 3,
      "severity": "important",
      "file": ".github/workflows/onefilellm.yml",
      "line": 1,
      "title": "Unsafe Auto-Merge of Untrusted Content",
      "description": "The workflow creates a Pull Request from external content and immediately attempts to auto-merge it using `gh pr merge --auto`. Automatically merging content derived from external, untrusted sources bypasses code review and can introduce malicious payloads, large files, or content that triggers vulnerability scanners/downstream processes.",
      "suggestion": "Remove the auto-merge step. Leave the Pull Request open for human inspection and approval before merging into the codebase."
    },
    {
      "id": 4,
      "severity": "important",
      "file": "tools/onefilellm/requirements.txt",
      "line": 1,
      "title": "Unpinned Dependency",
      "description": "The dependency `onefilellm>=0.1.0` is specified with an open-ended version range. In a workflow with `contents: write` permissions, this creates a supply chain risk. If a malicious version of `onefilellm` is published, it will be automatically installed and executed with write access to the repository.",
      "suggestion": "Pin the dependency to a specific version (e.g., `onefilellm==0.1.0`) to ensure build reproducibility and security."
    }
  ]
}
```